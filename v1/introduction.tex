\section{Introduction}
We have previously presented what we called a {\em logical graphical model}.
In this work, we further clarify that an important aspect of the model is that it is {\em probabilistic}.
Thus, we will now begin to refer to this as a ``logical probablistic model''.
The logical probabilistic model is a kind of a Bayesian Network.
One important problem that has always been a blocker for the practical use of Bayesian Networks is that the {\em structure} of a Bayesian Network must somehow be {\em specified}.
This is a problem that Neural Networks do not have.

This is a central point:
\begin{itemize}
    \item {\bf Mind-Blowing Insight}: The difference between neural networks and probabilistic graphical networks is that neural networks only require parameter training and inference, while probabilistic graphical models require inference, parameter learning and also something more difficult---the learning of the {\em structure} of the network.
\end{itemize}